C++ adheres to a standard. What that means is that the language has a well-defined implementation; the programmer knows what he can and can't rely on. It is still possible to write terrible code with C++, even though the language itself is compliant to ISO standards. Lots of important nuances are "implementation-defined" by the standard. Others are "unspecified" meaning there is a range of possible behaviors. An example of unspecified behavior is "new" ... the C++ creators have no idea which heap address you'll get. Lastly there is "undefined" behavior, the hackers favorite area. Once undefined behavior is triggered, the standard really has no idea what will happen. This chapter gives a basic overview of the C++ types, most of which I will not be documenting here. One notable exception is the wchar_t type, which is designed to hold wider character set encodings like Unicode. The size of wchar_t is implementation defined and large enough to hold the largest character set supported by the implementation's locale. The _t notation is usually used to indicate an alias, but in this case wchar_t is a distinct type. The choice for char meaning unsigned char or signed char is implementation defined, meaning that each unique implementation of the standard must provide a well-defined  behavior for the construct and that the behavior must be documented. In the code sample below, the use of implementation defined behavior leads to undefined behavior:

If the system you run this on a machine that defines char as unsigned, you'll see 255. On the other hand, running it on a machine where char is signed char, you'll see -1. "Attempts to ensure that some values are positive by declaring variables as unsigned will typically be defeated by the implicit conversion rules."  Unlike plain chars, plain ints are always signed. Using void* as a return type in a function declaration says that the return type is a pointer to object of unknown type. The reason for providing many different types (long int, long long int, unsigned long long int, etc) is to allow the programmer to take advantage of hardware features. Using the sizeof() function returns the size as a multiple of char size, typically an 8-bit byte. size_t is provided by cstddef, its an implementation defined unsigned integer type that can hold the size in bytes of every object. Another notable type in cstddef is ptrdiff_t which is used to hold the result of subtracting two pointers to get a number of elements. "The type's size is chosen so that it can store the maximum size of a theoretically possible array of any type." For example: 

An object doesn't just need enough space to hold its data. It also needs space for metadata and should be properly byte-aligned. The reason for alignment is efficiency of access; lots of hardware is designed to access data in chunks. Typically you won't come across issues here, but its very important to keep in mind when trying to write high performance code. You can view the byte alignment of built-in and user-defined types with alignof():

